# DSAN-6700-Assignment_1

## Project Directory Structure

```plaintext
.
├── Makefile                      # File to automate tasks like building, testing, etc.
├── README.md                     # Unified README for the entire project
├── build/                        # Directory for build artifacts (compiled files, etc.)
├── docs/                         # Documentation directory
│   ├── Makefile                  # Makefile for building the Sphinx documentation
│   ├── build/                    # Generated documentation files
│   │   ├── _sources/             # Documentation source files in RST format
│   │   ├── _static/              # Static files (CSS, JavaScript, images, etc.)
│   │   ├── doctrees/             # Intermediate files used by Sphinx
│   │   ├── genindex.html         # Generated index page for the documentation
│   │   ├── html/                 # Directory for HTML files
│   │   └── searchindex.js        # Search index for the documentation
│   ├── make.bat                  # Windows batch file for building the documentation
│   └── source/                   # Source directory for the documentation
│       ├── conf.py               # Sphinx configuration file
│       ├── index.rst             # Main documentation file (in reStructuredText format)
│       └── modules.rst           # Documentation for project modules
├── environment.yml               # Conda environment file for project dependencies
├── make.bat                      # Windows batch file for automated tasks
├── oryx-build-commands.txt       # Oryx build commands for deployment
├── poetry.lock                   # Locked dependency versions (generated by Poetry)
├── problem4/                     # Directory for Problem 4 (ML model training & inference)
│   ├── README.md                 # README for Problem 4
│   ├── build/                    # Build artifacts for the ML system
│   ├── iris_clusters.png         # Visual output of ML clustering
│   ├── iris_data.json            # JSON dataset for the ML model
│   ├── knn_model.pkl             # Trained KNN model pickle file
│   ├── ml_app/                   # Module for the ML application
│   │   ├── __init__.py           # Initialization file for the ML app module
│   │   ├── __main__.py           # Entry point for running the ML app
│   │   ├── __pycache__/          # Compiled Python files
│   │   ├── inference.py          # Inference logic for the ML model
│   │   ├── knn_model.pkl         # Trained KNN model used in inference
│   │   ├── tests/                # Unit tests for the ML app
│   │   │   ├── test_ml.py        # Unit tests for ML functionality
│   │   └── train.py              # Script for training the ML model
│   ├── out.json                  # Output file for model predictions
│   ├── public/                   # Directory for public-facing assets (e.g., HTML files)
│   │   └── index.html            # Public HTML file for viewing the ML model's output
│   └── visualize.py              # Script for visualizing the ML results
├── pyproject.toml                # Poetry configuration file for dependencies and project metadata
├── source/                       # Source files for documentation
│   ├── _static/                  # Static files (CSS, JavaScript, images) for documentation
│   ├── _templates/               # HTML templates for documentation
│   ├── conf.py                   # Sphinx configuration file for documentation
│   └── index.rst                 # Main documentation file for Sphinx
└── src/                          # Source code directory for both Problem 3 and Problem 4
    └── email_system/             # Module for Problem 3 (Email alert system)
        ├── alert.py              # Alert system logic
        └── mailer.py             # Email logic implementation
```

# Project Title: Email Alert & ML Modelling System

## Overview

1. **Email Alert System**:

This project provides an email alert system using a Python package that sends email notifications to users. The project is built with modern Python packaging techniques using `Poetry` and leverages `GitHub Actions` for Continuous Integration (CI). The email alert functionality is implemented through two Python scripts: `alert.py` and `mailer.py` under the directory `src/`. The `alert.py` script is responsible for sending email alerts, while the `mailer.py` script defines the email logic. The project also includes a pre-commit hook using `Ruff` to ensure that code is formatted correctly and adheres to best practices before it’s committed.

2. **ML Model System**:

The ML Model System focuses on training, performing inference, and visualizing a machine learning model on the Iris dataset using a K-Nearest Neighbors (KNN) classifier. The system includes scripts for each stage of the workflow: training the model, running inference on new data, and visualizing the results using UMAP for dimensionality reduction.

## Features

1. **Email Alert System**:

-   Send email alerts via a local SMTP server.
-   Structured as a Python package using `Poetry`.
-   Automatic formatting and linting using `pre-commit` hooks.
-   Continuous Integration (CI) pipeline with `GitHub Actions`.

2. **ML Model System**:

    **Model Training**:
    - The `train.py` script trains a KNN model on the Iris dataset using a specified train-test split ratio (default is 50%).
    - After training, the model is evaluated for accuracy, and the trained model is saved to a file (`knn_model.pkl`) for later use during inference.
    - The Iris dataset is split into training and test sets, and accuracy is computed based on the test set.

    **Inference**:
    - The `inference.py` script loads the saved KNN model (`knn_model.pkl`) and performs inference on new data provided via an environment variable (`DATA`).
    - The input data must be in JSON format, and the output predictions (including the input features and predicted labels) are saved to a file (`out.json`).

    **Visualization**:
    - The `visualize.py` script reduces the dimensionality of the Iris dataset using UMAP (Uniform Manifold Approximation and Projection) to generate 2D projections from the original 4D feature space.
    - The resulting visualization is created using Plotly and saved as both an interactive HTML file (`public/index.html`) and a static PNG image (`iris_clusters.png`).

    ### Usage Instructions

    #### 1. Train the Model

    To train the KNN model and save it for inference, run:

    ```bash
    poetry run python src/ml_app/train.py


### Steps

1.  Clone the repository:

    ``` 
    git clone https://github.com/jackyzhang1008/DSAN-6700-Assignment_1.git
    cd DSAN-6700-Assignment_1/problem_3
    ```

2.  Set up the virtual environment using Poetry: `poetry install`

3.  Start the local SMTP debugging server: `poetry run python -m smtpd -n -c DebuggingServer localhost:1025`

4.  In a separate terminal, run the email alert script: `poetry run python src/alert.py -s sender@example.com -r recipient@example.com -j "Subject" -b "Email Body` .After running the email alert script, the SMTP terminal will display the email message that was "sent." It won’t actually send the email, but you will see the details printed in the terminal.
