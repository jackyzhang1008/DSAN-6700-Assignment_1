.. mail_alerting and machine learning operations documentation master file, created by
   sphinx-quickstart on Wed Sep 18 12:21:51 2024.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.



.. mail_alerting and machine learning operations documentation
.. ===========================================================

.. Add your content using ``reStructuredText`` syntax. See the
.. `reStructuredText <https://www.sphinx-doc.org/en/master/usage/restructuredtext/index.html>`_
.. documentation for details.

DSAN-6700-Assignment_1
==========================



Project Directory Structure
===========================

Below is the project directory structure:

.. code-block:: none

    ├── Makefile                      # File to automate tasks like building, testing, etc.
    ├── README.md                     # Unified README for the entire project
    ├── build/                        # Directory for build artifacts (compiled files, etc.)
    ├── docs/                         # Documentation directory
    │   ├── Makefile                  # Makefile for building the Sphinx documentation
    │   ├── build/                    # Generated documentation files
    │   │   ├── _sources/             # Documentation source files in RST format
    │   │   ├── _static/              # Static files (CSS, JavaScript, images, etc.)
    │   │   ├── doctrees/             # Intermediate files used by Sphinx
    │   │   ├── genindex.html         # Generated index page for the documentation
    │   │   ├── html/                 # Directory for HTML files
    │   │   └── searchindex.js        # Search index for the documentation
    │   ├── make.bat                  # Windows batch file for building the documentation
    │   └── source/                   # Source directory for the documentation
    │       ├── conf.py               # Sphinx configuration file
    │       ├── index.rst             # Main documentation file (in reStructuredText format)
    │       └── modules.rst           # Documentation for project modules
    ├── environment.yml               # Conda environment file for project dependencies
    ├── make.bat                      # Windows batch file for automated tasks
    ├── oryx-build-commands.txt       # Oryx build commands for deployment
    ├── poetry.lock                   # Locked dependency versions (generated by Poetry)
    ├── problem4/                     # Directory for Problem 4 (ML model training & inference)
    │   ├── README.md                 # README for Problem 4
    │   ├── build/                    # Build artifacts for the ML system
    │   ├── iris_clusters.png         # Visual output of ML clustering
    │   ├── iris_data.json            # JSON dataset for the ML model
    │   ├── knn_model.pkl             # Trained KNN model pickle file
    │   ├── ml_app/                   # Module for the ML application
    │   │   ├── __init__.py           # Initialization file for the ML app module
    │   │   ├── __main__.py           # Entry point for running the ML app
    │   │   ├── __pycache__/          # Compiled Python files
    │   │   ├── inference.py          # Inference logic for the ML model
    │   │   ├── knn_model.pkl         # Trained KNN model used in inference
    │   │   ├── tests/                # Unit tests for the ML app
    │   │   │   ├── test_ml.py        # Unit tests for ML functionality
    │   │   └── train.py              # Script for training the ML model
    │   ├── out.json                  # Output file for model predictions
    │   ├── public/                   # Directory for public-facing assets (e.g., HTML files)
    │   │   └── index.html            # Public HTML file for viewing the ML model's output
    │   └── visualize.py              # Script for visualizing the ML results
    ├── pyproject.toml                # Poetry configuration file for dependencies and project metadata
    ├── source/                       # Source files for documentation
    │   ├── _static/                  # Static files (CSS, JavaScript, images) for documentation
    │   ├── _templates/               # HTML templates for documentation
    │   ├── conf.py                   # Sphinx configuration file for documentation
    │   └── index.rst                 # Main documentation file for Sphinx
    └── src/                          # Source code directory for both Problem 3 and Problem 4
        └── email_system/             # Module for Problem 3 (Email alert system)
            ├── alert.py              # Alert system logic
            └── mailer.py             # Email logic implementation


Overview
======================


1.  **Email Alert System**:

This project provides an email alert system using a Python package that sends email notifications to users. The project is built with modern Python packaging techniques using `Poetry` and leverages `GitHub Actions` for Continuous Integration (CI). The email alert functionality is implemented through two Python scripts: `alert.py` and `mailer.py` under the directory `src/`. The `alert.py` script is responsible for sending email alerts, while the `mailer.py` script defines the email logic. The project also includes a pre-commit hook using `Ruff` to ensure that code is formatted correctly and adheres to best practices before it’s committed.

2.  **ML Model System**:

The ML Model System focuses on training, performing inference, and visualizing a machine learning model on the Iris dataset using a K-Nearest Neighbors (KNN) classifier. The system includes scripts for each stage of the workflow: training the model, running inference on new data, and visualizing the results using UMAP for dimensionality reduction.

Features

1.  **Email Alert System**:

-   Send email alerts via a local SMTP server.
-   Structured as a Python package using `Poetry`.
-   Automatic formatting and linting using `pre-commit` hooks.
-   Continuous Integration (CI) pipeline with `GitHub Actions`.

2.  **ML Model System**:

    **Model Training**:

    -   The `train.py` script trains a KNN model on the Iris dataset using a specified train-test split ratio (default is 50%).
    -   After training, the model is evaluated for accuracy, and the trained model is saved to a file (`knn_model.pkl`) for later use during inference.
    -   The Iris dataset is split into training and test sets, and accuracy is computed based on the test set.

    **Inference**:

    -   The `inference.py` script loads the saved KNN model (`knn_model.pkl`) and performs inference on new data provided via an environment variable (`DATA`).
    -   The input data must be in JSON format, and the output predictions (including the input features and predicted labels) are saved to a file (`out.json`).

    **Visualization**:

    -   The `visualize.py` script reduces the dimensionality of the Iris dataset using UMAP (Uniform Manifold Approximation and Projection) to generate 2D projections from the original 4D feature space.
    -   The resulting visualization is created using Plotly and saved as both an interactive HTML file (`public/index.html`) and a static PNG image (`iris_clusters.png`).

    \### Usage Instructions

    \#### 1. Train the Model

    To train the KNN model and save it for inference, run:


### Steps

## Setting up:

This section walks through the implementation of the email alert system, which sends email notifications using Python. The system is built using `Poetry` for modern project packaging, with GitHub Actions integrated for Continuous Integration (CI).

1. Cloning the Repository 

    ``
    git clone https://github.com/your_username/DSAN-6700-Assignment_1.git
    cd DSAN-6700-Assignment_1
    ``

2. Setting up a virtual environment 

    ```
    python3 -m venv dsan-6700 # to create th environment
    conda env create -f environment.yml # to save it into the file for others to use it
    conda activate dsan-6700 # to activate the environment
    ```

3. Install Poetry and its dependencies 

    ```

    poetry install 

    ```


## Mail Alert System


1. Start Local SMTP Server 
This will start the local SMTP debugging server that will print the email content to the terminal instead of actually sending it

    ```
    
    poetry run python -m smtpd -n -c DebuggingServer localhost:1025

    ```

2. Send an email alert

We run the  `alert.py` works, make sure we run the following code to trigger an email notification 

    ```
    poetry run python src/email_system/alert.py -s sender@example.com -r recipient@example.com -j "Test Subject" -b "This is a test email."

    ```
* `Alert.py`: This script is responsible for gathering the necessary information (sender, recipient, subject, and body of the email) from the command line and passing it to the mailer.py module to actually send the email. 
* `Mailer.py`: This script contains the logic for constructing and sending the email using the SMTP (Simple Mail Transfer Protocol) protocol. It's a utility that can be reused by other parts of the application as well.

3. Continuous Integration (CI)
   
   The project uses GitHub Actions for CI to automate testing and code quality checks. The CI workflow is triggered when changes are pushed to the repository as `ci.yml`

## ML Model Systems 

1. Set up a virtual environment and train the model using the `train.py` which is used to train the KNN model 

    ```
    poetry run python problem4/train.py
    ```

2. Then perform inference using `inference.py` which loads the saved KNN model and performs inference on new data on new data using the trained KNN model
   
    ```
    poetry run python problem4/inference.py --data "out.json"

    ```
    The inferences here will be saved as `out.json`

3.  Visualise `visualize.py` script performs UMAP dimensionality reduction and generates a 2D visualization of the Iris dataset

    ```
    poetry run python problem4/visualize.py

    ```
The result will be saved as an image (iris_clusters.png) and an interactive HTML file (index.html).

4. Documentation : **Sphinx**

We use Sphinx for generating technical documentation. The documentation can be built locally and viewed as an HTML file. 

 * Install Dependencies
    ```
    poetry add sphinx
    ```
 * Build the Documentation 
    ```
    cd docs
    poetry run make html
    ```
The documentation will be generated in the docs/build/html/ directory.

  * We use GitHub Actions for CI automation. The CI pipeline runs every time new changes are pushed to the repository.
  
    We use GitHub Actions for CI automation, ensuring that the pipeline runs automatically whenever new changes are pushed to the repository. This allows us to enforce code quality, automate testing, and generate documentation. For the Email Alert System, the workflow is defined in mailer-ci.yml. The steps involve setting up an Ubuntu runner, installing Python 3.9, and using Poetry to install the project's dependencies. It then runs ruff to check code formatting and finally builds the documentation using Sphinx.

    For the ML Model System, the workflow is defined in ml_app-ci.yml. This workflow also sets up an Ubuntu runner and installs Python 3.9, followed by installing dependencies using Poetry. The pipeline then runs unit tests with pytest, trains the KNN model, performs inference on synthetic data, and finally builds and uploads the model artifacts. It also generates and publishes the project documentation to ReadTheDocs, ensuring that the documentation remains up to date with every new push.

readthedocs: [dsan-6700-assignment-1.readthedocs.io](http://dsan-6700-assignment-1.readthedocs.io/)


Project Documentation
======================

Welcome to the documentation for **DSAN 6700 Assignment 1**. This project consists of two main components:

1. **Email Alert System**: A Python-based system for sending email notifications.
2. **ML Model System**: A machine learning application that trains, infers, and visualizes a KNN model using the Iris dataset.

The documentation provides instructions on how to set up, use, and contribute to the project. Below is the table of contents to help navigate through the project documentation.

.. .. toctree::
..    :maxdepth: 2
..    :caption: Contents:

..     modules

Project Overview
================

###Email Alert System

The email alert system allows users to send automated email notifications using a local SMTP server. The system is implemented using modern Python packaging and includes unit tests for reliability.

###ML Model System

The ML Model System trains a K-Nearest Neighbors (KNN) model using the Iris dataset. The system includes scripts for training, inference, and visualization of the results. The visualizations use UMAP for dimensionality reduction, and the model is evaluated for accuracy before saving.

ML Model System Components
===========================

### Visualize.py

`visualize.py` performs dimensionality reduction on the Iris dataset using UMAP (Uniform Manifold Approximation and Projection) and creates an interactive 2D scatter plot with Plotly. The scatter plot highlights the different species within the Iris dataset, with the projections plotted in a two-dimensional graph.

#### Code Explanation

The script follows these steps:

1. **Load the Iris dataset**: It uses the built-in Iris dataset from `sklearn.datasets`.
2. **Apply UMAP**: The `UMAP` algorithm is used to reduce the dimensionality of the dataset.
3. **Create a scatter plot**: Using Plotly Express, it generates an interactive scatter plot where each point represents an observation from the Iris dataset, color-coded by species.
4. **Export the plot**: The plot is saved as an HTML file (`index.html`) in the `public` directory, making it easy to open in a browser for interactive exploration.

#### Requirements

Before running the script, make sure that you have the required dependencies installed in your conda environment. This project specifically requires the `dsan-6700` environment to be activated.

#####Activating the Conda Environment

To activate the `dsan-6700` environment, run the following command in your terminal:

```bash
conda activate dsan-6700

```



